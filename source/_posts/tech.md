---
title: Is Technology a proxy for progress?
date: 2023-05-29 
categories: [Philosophy]
index_img: /img/pprog.jpeg
excerpt: "Topic Stamps:
 1) Technologies: Definition & emergence.
 2) Philosophical tangent.
 3) 'Progress'
 4) Reconstructing the question.
 5) Meta-lesson/Conclusion."
---

This question of Whether technologies actually lead to progress is something that is often taken for granted or overlooked.

As technologies are extremely close to us in everyday life, the answer to the question might seem super clear, but there are super interesting philosophic considerations that might give us deep insights on the topic as a whole, and our question, as well.

This might be one of those questions where we need to spend an entire article with every word, like what is technology, what is progress, really ?

This question is the ultimate example of, as the cliché goes, “the journey is more important than the destination” (i.e. final answer).

In order to even scratch the surface of the question we need to actually understand why do technologies even emerge, in the first place ?


### Technologies: Definitions and emergence:

A technology is a lot of the times described (at least in our context) as a methodology of applying human insights and knowledge into the environment, and coming up with tools to serve different purposes.

I tend to take a bit of a different route than this definition, a more fundamental one, perhaps. 
I think a technology, at the most basic/abstract level, is really: a replicable control mechanism of the environment, and/or interactions in that environment, for a specific purpose.

For example, cars are a way to control the distance variable for humans and get to places faster.

Phones manipulate information and are one way to control communication between humans more. If I can communicate only when close-by to someone, I don’t have much control over the ways of communication, but if I invent a phone, I have more power over the way I can communicate to fellow man.


The latter definition I mentioned has within it the reasons why we actually apply knowledge to come up with technologies (i.e. to control variables at our disposal), which is why I tend towards it more. 

And we seek and try to look for those controllable variables by applying knowledge, science, experience, etc.  (which is implied in the former/first definition I mentioned).

It might seem very weird to perceive technologies in this way, but the reason why I put it this way is because it will make the answer to our question even easier to understand.

We might be getting ahead of ourselves here, but let’s just give a brief sneak-peak on where our answer might be going, specifically, in relationship to the definition so we don’t forget the point.

What we have come to realize is that “control” of the environment, which is done by technologies, might <b>sometimes</b> be a deceiving appearance. 

What happens sometimes is that we just, cleverly, and without knowing it, move the things we can’t control somewhere else we don’t see, rather than actually control the original problem, holistically.

A very proximal example in today’s world includes Social Media:

The invention of Social Media platforms was an invention for people to communicate, but Social Media created a whole package of social problems that weren’t considered, which one can think of as moving the problem of communication, or shifting it to the psychological/sociological realm. 

Which really means that the “lack of control” that was present, was merely moved to another domain, that itself requires control, if that makes sense.


### Interesting philosophical tangent:

Not to stray away too much, but there is another interesting idea we can link to our idea of control.

In his book, problems of a sociology of Knowledge, Max Scheler argued for the case that domination and control of one’s surroundings, <b>and self</b>, was actually the crux of the European Enlightenment period, as its popularly known.

What he argued was that all the ideas of Enlightenment, emerged for a will to dominate and control the surroundings, as well as, the human subject or the self.

The surroundings part shaped itself by  building tools and technologies using scientific knowledge, that can help man get more control over the external scene.

The self or the human subject part shaped itself by moving away from things that control man’s existence, such as the rise of individualism, and that “eliminated” external control of man, which in turn gave more control over oneself.

Scheler, takes this argument one step further and says that this has actually leaked itself into, interestingly enough, the state, as well.

Although it’s a bit of a reductionist point of view to look at the Enlightenment period through this lens only, but it’s pretty useful to boil down some common factors between technologies in this way. 

### Recapping:

So now that we have a somehow random perspective on what technologies are and have an idea on the basic assumption humans might have when different technologies are produced.

So now comes the question, does this method of controlling the environment lead to “progress” ?

This will lead us to actually go on another brief trip in exploring what people usually mean by “progress”. And then we can reconstruct our question more clearly by being on the same page with terminologies and their emergence.

### “Progress”:

Progress, as far as I see it, is almost always fundamentally used interchangeably with “change”, <b>except</b>, that, usually, there are good connotations intended with that change, when people use the word “progress” (whatever subjective “good” the speaker is attaching to it).

One other thing we have to acknowledge is that the concept of progress is fundamentally a relative one. You can’t have “progress” (or change) without measuring it against something, first.

You need to have a threshold or a measure to actually make sense of something like “progress”.

Now, the following two "metrics", we can say, are the ones that are often-times used as approximate measures for progress (they can be a lot of the times subconsciously assumed):

1) They’ll look towards the past, and compare it with present, so that’s one measure.

2) In our specific context, at least, the second measure on top of that is the amount of proximal “suffering” of the people, compared to the past, of course (the less suffering/more comfort, the more the “progress”, according to that measure).


### Reconstructing the question:

So now that we know the game when it comes to our definitions, let’s ask our question, does technology always lead to progress ?


Let’s tackle the question by proposing two opposing hypothetical views , and the we can construct where the truth probably lies and why.

View 1:
“Technology leads us to places we never thought we would be in as humans, it has lifted a lot of people out of poverty, and helped people live more comfortable lives. So I am all for technology !”

View 2:
“Technology is a great way to improve quality of life for humanity and purport achievements, However, we have to understand each technology and see what are their long-term externalities.”

So as we probably somehow alluded to before, view 2 is closer to being more correct, 
here is why:

 <b>1</b>) I think View 2 is an attempt to look at the whole picture, rather than a pixel. 

One can’t deny that technologies lead to “progress”, or as the measure we set towards progress, “reduces suffering”, but to think that it's the entire full picture, is a shallow way to look at the world.

Progress, or “lack of suffering” can be easily off-set in the future by socialising risks that might add up to be a net-negative, which eventually cancels out all the “progress” that certain people witnessed (assuming we define progress based on the measures we set forward).


A good example of this is leaded fuel.

When leaded fuel, which was used for vehicles, (which we can hypothetically think of as a technology) made it to the markets in the 1920’s,

It was increasing vehicles efficiency and everything was great for the people at the time. But years later, lead was discovered in people’s blood, and it was causing all sorts of health and intellectual problems in the world.

Perhaps this is an extreme example, but hopefully it shows us how we can think that something “can reduce the suffering”, or “lead to progress” (no pun intended), when in fact it can very much push the “suffering” to another domain, or in another time, and that might precipitously cause existential risks or even collapse.


<b>2)</b> The world is extremely interconnected, anything we try to do affects everything else, to a degree. We have to be cognizant of , and try to understand, the high-order effects that we don’t see in the present, when we build technologies or do anything for that matter, as history has proved time and time again.


In an interconnected complex world, control is an illusion, to a degree. Since the world is interconnected and complex in every way possible, what we do sometimes is we displace the problem somewhere else we don’t visibly see, rather than solve it with “technology”, as we might think.

Of course, the degree to which the other problem is going to be more of a “pain”, is something up for debate, and asking to what degree and why, are the right questions to ask.


### Random directions at tackling such issues:

Solving issues like the risks of exponential technologies, is multi-faceted and has all sorts of directions to tackle. 


We can’t have people weighing societal risks of exponentially increasing technologies, when the Socioeconomic (with an emphasis on the Economic side) incentives are all pointed towards the direction of profit no matter what (“maximize the profits, socialize the risks” type of model).

It might also seem like “view 2” we discussed is really purporting a “slowing down” of technologies, but it’s much deeper than that.

It’s appealing to what is possible.

If we <b>can</b>, to a degree, predict the risks of man-made technologies, <b>if we take the extra miles and measures while building them and refining them</b>, and we do know that they actually have risks, then that possibility should be a good enough reason for the discussion to be had on our approach towards technologies, and to assess the benefits of society, rather than focus on the very close-by game-theoretic advantages we might enjoy.

This is, to a degree, easier said than done, as a shift towards building Human-values conscious technologies requires whole socioeconomic systems (as alluded to) to change its approach, to a degree.

Which in turn is an extremely difficult problem to solve and think about, which I’ll hopefully try to think about and write about more.

I want to take some time to say that really what we provided is not even a close trial to a full “solution”, but it's rather to shed light on the issues and what the solutions might remotely look like.


### Meta-lesson/conclusion:

We saw that “progress” is really a deep concept that perhaps requires more thought than it is accredited with. 

One thing we can extract from this is that, perhaps contrary to common belief, technologies are seldom “Black” or “White”, really (like a lot of other things).

But in order to shift it towards the “Benign/good” side of things, we need to understand how it can give rise harmful consequences (sometimes as side-effects), and shift the approach to technologies to be more salutary, to the degree that that’s possible.
